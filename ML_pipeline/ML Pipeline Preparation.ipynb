{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "# download libraries if necessary\n",
    "# nltk.download(['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger'])\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///CleanDatabase.db')\n",
    "df = pd.read_sql_table('cleaned_data', engine)\n",
    "X = df['message']\n",
    "y = df.drop(['id', 'message', 'original', 'genre'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\" Function to process text in the following order: normalize, tokenize, \n",
    "        remove stop words, and lemmatize.\n",
    "    Args:\n",
    "        text (str): text to be processed\n",
    "    Returns:\n",
    "        tokens (list): list of tokens after processing text\n",
    "    \"\"\"\n",
    "\n",
    "    # normalize text by removing punctuation and converting to lower case\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # remove stop words and lemmatize\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word)\n",
    "              for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(KNeighborsClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=KNeighborsClassifier()))])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "def get_report(y_test, y_pred):\n",
    "    \"\"\" Function that compares the predicted labels to the test labels returning the mean accuracy, \n",
    "        f1-score macro average and f1-score weighted average of the model.\n",
    "    Args:\n",
    "        y_test (DataFrame): test labels\n",
    "        y_pred (DataFrame): predicted labels\n",
    "    Returns:\n",
    "        (DataFrame): mean accuracy, f1-score macro average and f1-score weighted average of labels\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    for column in y_test.columns:\n",
    "        report = classification_report(\n",
    "            y_test[column], y_pred[column], output_dict=True)\n",
    "        results.append([report['accuracy'], report['macro avg']\n",
    "                        ['f1-score'], report['weighted avg']['f1-score']])\n",
    "\n",
    "    index = y_test.columns\n",
    "    columns = ['accuracy', 'f1-score macro avg', 'f1-score weighted avg']\n",
    "\n",
    "    return pd.DataFrame(results, index=index, columns=columns).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy                 0.928883\n",
       "f1-score macro avg       0.512088\n",
       "f1-score weighted avg    0.900306\n",
       "dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results\n",
    "results = get_report(y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.229, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.204, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.235, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.239, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.256, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.216, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  8.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.197, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  9.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.233, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 11.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.234, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 12.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.249, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.229, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.207, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.232, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.238, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.256, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.216, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.197, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.235, total= 1.5min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.235, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=20, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.247, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.229, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.204, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.235, total= 1.3min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.239, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 1), score=0.256, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.216, total= 2.1min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.197, total= 4.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.233, total= 4.2min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.234, total= 4.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=True, vect__ngram_range=(1, 2), score=0.249, total= 4.3min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.229, total= 3.8min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.207, total= 3.8min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.232, total= 3.8min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.238, total= 2.5min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 1), score=0.256, total= 1.5min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.216, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.197, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.235, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.235, total= 1.4min\n",
      "[CV] clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__leaf_size=40, tfidf__sublinear_tf=False, vect__ngram_range=(1, 2), score=0.247, total= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 75.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x000001F6F40FF558>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=KNeighborsClassifier()))]),\n",
       "             param_grid={'clf__estimator__leaf_size': (20, 40),\n",
       "                         'tfidf__sublinear_tf': (True, False),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'tfidf__sublinear_tf': (True, False),\n",
    "    'clf__estimator__leaf_size': (20, 40),\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=10)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__leaf_size': 20,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline using best parameters\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 1))),\n",
    "    ('tfidf', TfidfTransformer(sublinear_tf=False)),\n",
    "    ('clf', MultiOutputClassifier(KNeighborsClassifier(leaf_size=20)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=KNeighborsClassifier(leaf_size=20)))])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy                 0.946828\n",
       "f1-score macro avg       0.625059\n",
       "f1-score weighted avg    0.935607\n",
       "dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "# convert y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = y_test.columns\n",
    "\n",
    "# check results\n",
    "results = get_report(y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline using RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy                 0.948079\n",
       "f1-score macro avg       0.620252\n",
       "f1-score weighted avg    0.936225\n",
       "dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# convert y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = y_test.columns\n",
    "\n",
    "# check results\n",
    "results = get_report(y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 1) ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 1), score=0.273, total= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 1) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 1), score=0.259, total= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 11.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 1) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 1), score=0.266, total= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 18.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 1) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 1), score=0.256, total= 7.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 25.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 1) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 1), score=0.282, total= 7.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 32.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 2) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 2), score=0.276, total=18.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 51.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 2) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 2), score=0.268, total=19.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 70.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 2) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 2), score=0.265, total=19.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 90.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 2) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 2), score=0.263, total=14.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 104.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__bootstrap=True, vect__ngram_range=(1, 2) ........\n",
      "[CV]  clf__estimator__bootstrap=True, vect__ngram_range=(1, 2), score=0.276, total=16.3min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 1) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 1), score=0.270, total= 7.5min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 1) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 1), score=0.263, total= 7.6min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 1) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 1), score=0.267, total= 7.6min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 1) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 1), score=0.260, total= 7.9min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 1) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 1), score=0.275, total= 8.0min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 2) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 2), score=0.276, total=23.5min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 2) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 2), score=0.273, total=26.3min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 2) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 2), score=0.268, total=31.2min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 2) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 2), score=0.268, total=31.5min\n",
      "[CV] clf__estimator__bootstrap=False, vect__ngram_range=(1, 2) .......\n",
      "[CV]  clf__estimator__bootstrap=False, vect__ngram_range=(1, 2), score=0.283, total=23.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 295.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x000001F6F40FF558>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             param_grid={'clf__estimator__bootstrap': (True, False),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'clf__estimator__bootstrap': (True, False),\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=10)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__bootstrap': False, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline using best parameters\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(bootstrap=False)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                 tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=False)))])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy                 0.947037\n",
       "f1-score macro avg       0.625294\n",
       "f1-score weighted avg    0.935779\n",
       "dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# convert y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = y_test.columns\n",
    "\n",
    "# check results\n",
    "results = get_report(y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        \"\"\" Function that takes in a text message string and returns True if the first word is a verb.\n",
    "        Args:\n",
    "            text (str): string containing text message\n",
    "        Returns:\n",
    "            (bool): True if first word of sentence is a verb\n",
    "        \"\"\"\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        for sentence in sentence_list:\n",
    "            tokens = word_tokenize(sentence)\n",
    "            clean_tokens = []\n",
    "            for token in tokens:\n",
    "                clean_tokens.append(\n",
    "                    lemmatizer.lemmatize(token).lower().strip())\n",
    "            pos_tags = nltk.pos_tag(clean_tokens)\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP']:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Function that takes in a series of messages and returns a dataframe with starting_verb() applied\n",
    "            to each message.\n",
    "        Args:\n",
    "            X (Series): list of messages\n",
    "        Returns:\n",
    "            (DataFrame): boolean values indicating if first word in the messages is a verb\n",
    "        \"\"\"\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Function that takes in a series of messages and returns a dataframe containing the message lengths.\n",
    "        Args:\n",
    "            X (Series): list of messages\n",
    "        Returns:\n",
    "            (DataFrame): integer values representing message lengths\n",
    "        \"\"\"\n",
    "        X_len = pd.Series(X).apply(len)\n",
    "        return pd.DataFrame(X_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline with both transformers\n",
    "pipeline = Pipeline([\n",
    "    ('feature', FeatureUnion([\n",
    "        ('nlp_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('sve', StartingVerbExtractor()),\n",
    "        ('tle', TextLengthExtractor())\n",
    "    ])\n",
    "    ),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(bootstrap=False)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature',\n",
       "                 FeatureUnion(transformer_list=[('nlp_pipeline',\n",
       "                                                 Pipeline(steps=[('vect',\n",
       "                                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                                               2),\n",
       "                                                                                  tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfTransformer())])),\n",
       "                                                ('sve',\n",
       "                                                 StartingVerbExtractor()),\n",
       "                                                ('tle',\n",
       "                                                 TextLengthExtractor())])),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=False)))])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy                 0.947093\n",
       "f1-score macro avg       0.623521\n",
       "f1-score weighted avg    0.935540\n",
       "dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# convert y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = y_test.columns\n",
    "\n",
    "# check results\n",
    "results = get_report(y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StartingVerbExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline with only StartingVerbExtractor\n",
    "pipeline = Pipeline([\n",
    "    ('feature', FeatureUnion([\n",
    "        ('nlp_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('sve', StartingVerbExtractor())\n",
    "    ])\n",
    "    ),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(bootstrap=False)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature',\n",
       "                 FeatureUnion(transformer_list=[('nlp_pipeline',\n",
       "                                                 Pipeline(steps=[('vect',\n",
       "                                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                                               2),\n",
       "                                                                                  tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfTransformer())])),\n",
       "                                                ('sve',\n",
       "                                                 StartingVerbExtractor())])),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=False)))])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy                 0.946867\n",
       "f1-score macro avg       0.624798\n",
       "f1-score weighted avg    0.935581\n",
       "dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# convert y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = y_test.columns\n",
    "\n",
    "# check results\n",
    "results = get_report(y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextLengthExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline with only TextLengthExtractor\n",
    "pipeline = Pipeline([\n",
    "    ('feature', FeatureUnion([\n",
    "        ('nlp_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('tle', TextLengthExtractor())\n",
    "    ])\n",
    "    ),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(bootstrap=False)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature',\n",
       "                 FeatureUnion(transformer_list=[('nlp_pipeline',\n",
       "                                                 Pipeline(steps=[('vect',\n",
       "                                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                                               2),\n",
       "                                                                                  tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfTransformer())])),\n",
       "                                                ('tle',\n",
       "                                                 TextLengthExtractor())])),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=False)))])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy                 0.946920\n",
       "f1-score macro avg       0.623124\n",
       "f1-score weighted avg    0.935304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# convert y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = y_test.columns\n",
    "\n",
    "# check results\n",
    "results = get_report(y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom features added do not improve the model, hence we will choose the model having best parameters for the random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                 tokenizer=<function tokenize at 0x000001F72C0BB1F8>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=False)))])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build pipeline using best parameters\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(bootstrap=False)))\n",
    "])\n",
    "\n",
    "# train pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model as pickle file\n",
    "import pickle\n",
    "\n",
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
